{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribución estacionaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el notebook 05, vimos que la distribución de probabilidad $\\mathbf{\\mu}_t$ de una cadena de Markov tiende a acercarse (*converger*), cuando $t \\to \\infty$, a una distribución de probabilidad que podemos denotar $\\mathbf{\\mu}_\\infty$.  [Usaremos la notación $\\mu$ (de \"medida\") para evitar que haya tantos P's.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] (i) Escribe la ecuación que gobierna la evolución de $\\mathbf{\\mu}_t$, y de ahí obtiene una ecuación para $\\mathbf{\\mu}_\\infty$.\n",
    "\n",
    "(ii) ¿Cómo se relacion $\\mathbf{\\mu}_\\infty$ con la matriz de transición $\\mathsf{P}$ de la cadena?\n",
    "\n",
    "(iii) Demuestra que si empezamos con la distribución $\\mathbf{\\mu}_\\infty$, la distribución a cualquier tiempo será la misma. \n",
    "\n",
    "(iv) Debido a ello, llamamos a $\\mathbf{\\mu}_\\infty$ una *distribución estacionaria* de la cadena. se puede demostrar que existe y es única si la cadena satisface dos propiedades técnicas, que sea *aperiódica* e *irreducible*.\n",
    "\n",
    "Busca y explica estas dos propiedades de una cadena de Markov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] Dada una matriz de transición $\\mathsf{P}$, ¿cómo podemos calcular de forma numérica la distribución estacionaria correspondiente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] Reescribe la expresión de estacionariedad para un estado dado, $i$, de la cadena. Interpreta esta expresión físicamente. Esta propiedad se llama *balance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] ¿Qué tan rápido convergerá una cadena de Markov a distribución estacionaria?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacia MCMC: Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el resto del curso, estaremos ocupados con una pregunta distinta:\n",
    "\n",
    "*Dada* una distribución de probabilidad $\\pi$ sobre un conjunto $S := \\{s_1, \\ldots, s_k\\}$, ¿cómo podríamos *diseñar* un proceso estocástico tal que tenga la distribución $\\pi$, y así *simular* el sistema con la distribución requerida?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] ¡Responde esta pregunta!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##- Respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $\\mu_0$ es la distribuci\\'on de probabilidad inicial de nuestro sistema, si la matriz de transici\\on es $\\mathbb{P}$ la ecuaci\\'on para $\\mu_t$ ser\\'a:\n",
    "\\begin{equation}\n",
    "\\mu_t=\\mathbb{P}^{t-1} \\mu_0\n",
    "\\end{equation}\n",
    "Por lo tanto la distribuci\\'on en equilibrio estar\\'a dada por:\n",
    "\\begin{equation}\n",
    "\\lim_{t\\rightarrow\\infty}\\mu_{t+1}=\\lim_{t\\rightarrow\\infty}\\mathbb{P}\\mu_t\n",
    "\\end{equation}\n",
    "Esto es:\n",
    "\\begin{equation}\n",
    "\\mu_{\\infty}=\\mathbb{P}\\mu_{\\infty}\n",
    "\\end{equation}\n",
    "Por la distribuci\\'on de equilibrio es el vector propio de $\\mathbb{P}$ con valor propio 1. \n",
    "Si empezamos con $\\mu_{\\infty}$ entonces $\\mu_{\\infty}=(\\lim_{t\\rightarrow\\infty}\\mathbb{P^{t}})\\mu_{\\infty}=\\lim_{t\\rightarrow\\infty}(\\mathbb{P}^{t}\\mu_{\\infty})$, por lo tanto $\\mathbb{P}^t\\mu_{\\infty}=\\mu_{\\infty} \\forall t$, i.e., $\\mu_{t+1}=\\mathbb{P}^{t}\\mu_{\\infty}=\\mu_{\\infty} \\forall t$\n",
    "\n",
    "- Irreducible: Una cadena de markov es irreducible si se puede llegar a cualquier estado empezando en cualquier otro estado en un tiempo finito.\n",
    "- Aperiódica: Una cadena de markov se dice aperiódica si todos sus estados son aperiódicos, esto es, para cada estado i la única probabilidad distinta de cero que en n pasos regrese a ese estado es cuando n=1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2.-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que $\\mu_{\\infty}=\\lim_{t\\rightarrow\\infty}\\mathbb{P}^{t-1}\\mu_0$, no importando cúal sea $\\mu_0$, por lo tanto podemos iniciar con $\\mu_0=[1,0,....]$, e iterar $\\mu_t=\\mathbb{P}^{t-1}\\mu_0$, haciendo es iteración con un paso de corte ($|\\mu_t-\\mu_{t-1}|<\\epsilon$) a partir del cual ya llegaste al estado estacionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ecuación de balance es $\\mathbb{P}_{ij}(\\mu)_i=\\mathbb{P}_{ji}(\\mu)_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las cadenas de markov convergen exponencialmente, su error decrece exponencialmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos generar una cadena de markov cuyos elementos de la matriz de transición cumplan la ecuación de balance con la distribución deseada, esto es:\n",
    "\\begin{equation}\n",
    " \\mathbb{P}_{ij}(\\pi)_i=\\mathbb{P}_{ji}(\\pi)_j\n",
    "\\end{equation}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.6-pre",
   "language": "julia",
   "name": "julia 0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
