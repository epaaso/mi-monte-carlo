{
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.7-pre",
   "language": "julia",
   "name": "julia 0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.7"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Cadenas de Markov "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Un caminante aleatorio es un tipo particular de una *cadena de Markov*.\n",
      "\n",
      "Una cadena de Markov es, a su vez, un tipo de \n",
      "*proceso estoc\u00e1stico*, es decir una evoluci\u00f3n en \n",
      "el tiempo que no es determinista, sino donde hay \n",
      "una probabilidad dada, el sistema lleva a cabo \n",
      "una *transici\u00f3n* hacia un estado nuevo. Las cadenas de Markov son de gran importancia hoy d\u00eda en las ciencias.\n",
      "\n",
      "La particularidad de las cadenas de Markov es que satisfacen la *propiedad de Markov*: el estado nuevo depende *s\u00f3lo de un estado anterior*. Se suele decir que el proceso *no tiene memoria*.\n",
      "\n",
      "Por ejemplo, una caminata aleatoria satisface esto, ya que la posici\u00f3n al tiempo $t+1$ depende s\u00f3lo de la posici\u00f3n al tiempo $t$ (no de posiciones a tiempos anteriores).  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sea $X_n$ el estado del proceso al tiempo $n$. Nos interesaremos por el momento en procesos de Markov tal que\n",
      "$P(X_{n+1} = j \\, | \\, X_n = i) = p_{ij}$, independiente del tiempo. La notaci\u00f3n aqu\u00ed es de una *probabilidad condicional*, es decir, la probabilidad de que el sistema est\u00e1 en el estado $j$ al tiempo $n+1$, *dado que* estaba en el estado $i$ al tiempo $n$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[1] Las $p_{ij}$ forman una matriz. \n",
      "\n",
      "(i) Escribe la matriz para un caminante aleatorio con fronteras reflejantes en 0 y $L=5$, si tiene probabilidades $p$, $q$, y $r$ de brincar a la derecha o izquierda, o de permanecer en el mismo lugar, respectivamente.\n",
      "\n",
      "(ii) \u00bfQu\u00e9 propiedad debe satisfacer cualquier matriz de transici\u00f3n?\n",
      "\n",
      "[2] Considera una cadena que tiene 4 estados. Desde cada estado puede brincar a cada otro estado con igual probabilidad. \n",
      "\n",
      "(i) Escribe la matriz de transici\u00f3n $\\mathsf{P} = (p_{ij})$. \u00bfQu\u00e9 propiedades tiene que satisfacer?\n",
      "\n",
      "(ii) \u00bfQu\u00e9 tipo de propiedades nos podr\u00edan interesar?, suponiendo que esto modela un estado f\u00edsico, qu\u00edmico o biol\u00f3gico que puede estar en uno de estos estados.\n",
      "\n",
      "(iii) Simula la din\u00e1mica del sistema: escribe una funci\u00f3n que genera una realizaci\u00f3n de cierta longitud.\n",
      "\n",
      "(iv) Escribe funciones que calculen las cantidades de interes num\u00e9ricamente.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[3] Escribe una funci\u00f3n para simular una realizaci\u00f3n de una trayectoria correspondiendo a una matriz de transici\u00f3n *arbitraria* $\\mathsf{P}$ que satisfaga las propiedades de 2(i)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "M\u00e9todo estilo enumeraci\u00f3n exacta"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tal como hicimos para un caminante aleatorio, para una cadena de Markov tambi\u00e9n podemos cambiar de punto de vista y estudiar la evoluci\u00f3n de la *distribuci\u00f3n de probabilidad*, la cual nos dice la probabilidad de que la cadena se encuentra en cada estado al tiempo $t$.\n",
      "\n",
      "Primero veamos esto anal\u00edticamente."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[4] Supongamos que la cadena empieza en alguna distribuci\u00f3n de probabilidad inicial $\\mathbf{P}_0 = (P_{0,i}: i=1, \\ldots, n)$, donde $n$ es el n\u00famero de estados.\n",
      "\n",
      "(i) Escribe la ecuaci\u00f3n maestra que describe c\u00f3mo evoluciona la probabilidad en 1 paso.  \n",
      "\n",
      "(ii) Escr\u00edbela de nuevo, ahora usando notaci\u00f3n matricial.\n",
      "\n",
      "(ii) \u00bfQu\u00e9 pasa en 2 pasos? \u00bfEn $N$ pasos?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[5] Simula la din\u00e1mica de la cadena de Markov de la pregunta 2 desde una condici\u00f3n inicial que es una delta en alg\u00fan estado por un tiempo $t$. \u00bfQu\u00e9 observas cuando $t \\to \\infty$?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[6] Este mismo fen\u00f3meno (lo que pasa cuando $t \\to \\infty$) ocurre para \"casi todas\" las cadenas de Markov (cuando se satisfacen ciertas condiciones t\u00e9cnicas). Expl\u00edcalo usando propiedades de la matriz que vieron en \u00e1lgebra lineal. \u00bfA qu\u00e9 corresponde lo que pasa cuando $t \\to \\infty$?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}